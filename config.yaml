rd_alpha: 
  desc: The first minimal-viable-product of wisdomify. Trained on wisdom2def only. S_wisdom = S_wisdom_literal
  a:
    bert: beomi/kcbert-base
    desc: The first version of RDAlpha - trained on `wisdom2def:a`
    seed: 410
    train_type: wisdom2def
    train_ver: a
    wisdoms_ver: a
    val_test_ver: a
    k: 11
    lr: 0.00001
    max_epochs: 100
    batch_size: 64
    num_workers: 4
    shuffle: true
    log_every_n_steps: 2
    enable_checkpointing: false
    num_sanity_val_steps: 0
  b: 
    bert: beomi/kcbert-base
    desc: The second version RDAlpha - trained on `wisdom2def:b`
    seed: 410
    train_type: wisdom2def
    train_ver: b
    wisdoms_ver: a
    val_test_ver: a
    k: 11
    # this is an optimised value: refer to: magic-water-909 
    lr: 0.000003631
    max_epochs: 100
    batch_size: 64
    num_workers: 4
    shuffle: true
    log_every_n_steps: 1
    enable_checkpointing: false
    num_sanity_val_steps: 0
  c: 
    bert: kykim/bert-kor-base
    desc: the second version of RDBeta - trained on `wisdom2def:b`
    seed: 410
    train_type: wisdom2def
    train_ver: b
    wisdoms_ver: a
    val_test_ver: a
    k: 11
    lr: 0.00001
    max_epochs: 100
    batch_size: 64
    num_workers: 4
    shuffle: true
    log_every_n_steps: 1
    enable_checkpointing: false
    num_sanity_val_steps: 0
rd_beta: 
  desc: The second version of RD. S_wisdom = S_wisdom_literal + S_wisdom_figurative.
  a: 
    bert: beomi/kcbert-base
    desc: the first version of RDBeta - trained on `wisdom2def:a`
    seed: 410
    train_type: wisdom2def
    train_ver: a
    wisdoms_ver: a
    val_test_ver: a
    k: 11
    lr: 0.00001
    max_epochs: 100
    batch_size: 64
    num_workers: 4
    shuffle: true
    log_every_n_steps: 1
    enable_checkpointing: false
    num_sanity_val_steps: 0
  b: 
    bert: beomi/kcbert-base
    desc: the second version of RDBeta - trained on `wisdom2def:b`
    seed: 410
    train_type: wisdom2def
    train_ver: b
    wisdoms_ver: a
    val_test_ver: a
    k: 11
    # refer to: apricot-galaxy-911
    lr: 0.000001445
    max_epochs: 100
    batch_size: 64
    num_workers: 4
    shuffle: true
    log_every_n_steps: 1
    enable_checkpointing: false
    num_sanity_val_steps: 0
rd_gamma:
  desc: The third version of RD. S_wisdom = S_wisdom_literal + S_wisdom_figurative (much simplified)
  a_attention:
    bert: beomi/kcbert-base
    desc: the first version of RDGamma - trained on `wisdom2def:a`
    seed: 410
    train_type: wisdom2def
    train_ver: a
    wisdoms_ver: a
    val_test_ver: a
    k: 11
    lr: 0.00001
    pooler_size: 30
    mode: attention
    max_epochs: 100
    batch_size: 64
    num_workers: 4
    shuffle: true
    log_every_n_steps: 1
    enable_checkpointing: false
    num_sanity_val_steps: 0
  a_pooling:
    bert: beomi/kcbert-base
    desc: the first version of RDGamma - trained on `wisdom2def:a`
    seed: 410
    train_type: wisdom2def
    train_ver: a
    wisdoms_ver: a
    val_test_ver: a
    k: 11
    lr: 0.00001
    pooler_size: 30
    mode: pooling
    max_epochs: 100
    batch_size: 64
    num_workers: 4
    shuffle: true
    log_every_n_steps: 1
    enable_checkpointing: false
    num_sanity_val_steps: 0
  b_attention:
    bert: beomi/kcbert-base
    desc: the second version of RDGamma - the same as version a, but with increased epochs
    seed: 410
    train_type: wisdom2def
    train_ver: b
    wisdoms_ver: a
    val_test_ver: a
    k: 11
    lr: 0.00001
    pooler_size: 30
    mode: attention
    max_epochs: 100
    batch_size: 64
    num_workers: 4
    shuffle: true
    log_every_n_steps: 1
    enable_checkpointing: false
    num_sanity_val_steps: 0
  b_pooling:
    bert: beomi/kcbert-base
    desc: the second version of RDGamma - the same as version a, but with increased epochs
    seed: 410
    train_type: wisdom2def
    train_ver: b
    wisdoms_ver: a
    val_test_ver: a
    k: 11
    lr: 0.00001
    pooler_size: 30
    mode: pooling
    max_epochs: 100
    batch_size: 64
    num_workers: 4
    shuffle: true
    log_every_n_steps: 1
    enable_checkpointing: false
    num_sanity_val_steps: 0
  c_attention:
    bert: beomi/kcbert-base
    desc: the same as b, but with max_epochs = 100 & pooler size = hidden_size
    seed: 410
    train_type: wisdom2def
    train_ver: b
    wisdoms_ver: a
    val_test_ver: a
    k: 11
    lr: 0.00001
    pooler_size: 768
    mode: attention
    max_epochs: 100
    batch_size: 64
    num_workers: 4
    shuffle: true
    log_every_n_steps: 1
    enable_checkpointing: false
    num_sanity_val_steps: 0
  c_pooling:
    bert: beomi/kcbert-base
    desc: the same as b, but with max_epochs = 100 & pooler size = hidden_size
    seed: 410
    train_type: wisdom2def
    train_ver: b
    wisdoms_ver: a
    val_test_ver: a
    k: 11
    # refer to: dainty-snow-910
    lr: 0.000003631
    pooler_size: 768
    mode: pooling
    max_epochs: 100
    batch_size: 64
    num_workers: 4
    shuffle: true
    log_every_n_steps: 1
    enable_checkpointing: false
    num_sanity_val_steps: 0
  c_both:
    bert: beomi/kcbert-base
    desc: the same as b, but with max_epochs = 100 & pooler size = hidden_size
    seed: 410
    train_type: wisdom2def
    train_ver: b
    wisdoms_ver: a
    val_test_ver: a
    k: 11
    lr: 0.00001
    pooler_size: 768
    mode: both
    max_epochs: 100
    batch_size: 64
    num_workers: 4
    shuffle: true
    log_every_n_steps: 1
    enable_checkpointing: false
    num_sanity_val_steps: 0
